{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4704940e-3481-4db7-b325-7ec6a8761820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import spacy\n",
    "!spacy download en_core_web_sm  \n",
    "\n",
    "import os\n",
    "import re\n",
    "from spacy import displacy\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bbffd61-65a9-4a6c-a95f-42835cdbc982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load corpus files\n",
    "corpus_path = '/Users/minjacvetkovski/Documents/DH MA/Collecting data/A2/corpus'\n",
    "\n",
    "texts = []\n",
    "file_names = []\n",
    "\n",
    "for _file_name in os.listdir(corpus_path):\n",
    "    if _file_name.endswith('.txt'):\n",
    "        path = os.path.join(corpus_path, _file_name)\n",
    "        text = open(path, 'r', encoding='utf-8').read()\n",
    "        texts.append(text)\n",
    "        file_names.append(_file_name)\n",
    "\n",
    "#Create DataFrame \n",
    "final_paper_df = pd.DataFrame({\n",
    "    'Filename': file_names,\n",
    "    'Document': texts \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6498a1a5-ca00-400a-908e-ac64a79c89a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing text\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Lowercase text, normalize common contractions, remove extra spaces.\"\"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    #Dictionary of contractions and informal words to normalized form\n",
    "    contractions = {\n",
    "        \"who's\": \"who is\", \"what's\": \"what is\", \"she's\": \"she is\", \"he's\": \"he is\",\n",
    "        \"it's\": \"it is\", \"that's\": \"that is\", \"there's\": \"there is\", \"i'm\": \"i am\",\n",
    "        \"i've\": \"i have\", \"i'll\": \"i will\", \"you've\": \"you have\", \"you're\": \"you are\",\n",
    "        \"we're\": \"we are\", \"they're\": \"they are\", \"can't\": \"cannot\", \"don't\": \"do not\",\n",
    "        \"doesn't\": \"does not\", \"didn't\": \"did not\", \"won't\": \"will not\", \"wouldn't\": \"would not\",\n",
    "        \"shouldn't\": \"should not\", \"couldn't\": \"could not\", \"'cause\": \"because\", \"’cause\": \"because\",\n",
    "        \"gonna\": \"going to\", \"wanna\": \"want to\", \"gotta\": \"have got to\", \"owt\": \"anything\",\n",
    "        \"summat\": \"something\", \"starin'\": \"staring\", \"drivin'\": \"driving\", \"givin'\": \"giving\",\n",
    "        \"pullin'\": \"pulling\", \"goin'\": \"going\", \"fuckin'\": \"fucking\", \"dancin'\": \"dancing\",\n",
    "        \"clingin'\": \"clinging\", \"soundin'\": \"sounding\", \"takin'\": \"taking\", \"makin'\": \"making\",\n",
    "        \"smudgin'\": \"smudging\", \"askin'\": \"asking\", \"havin'\": \"having\",\n",
    "        \"she dont\": \"she does not\", \"he dont\": \"he does not\", \"it dont\": \"it does not\"\n",
    "    }\n",
    "    \n",
    "    for contraction, full_form in contractions.items():\n",
    "        text = re.sub(r'\\b{}\\b'.format(re.escape(contraction)), full_form, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    #Remove extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "#Apply preprocessing\n",
    "final_paper_df['Text'] = final_paper_df['Document'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8917e35-ed8d-43df-9233-96f64fe22dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load metadata and merge\n",
    "metadata_path = os.path.join(corpus_path, 'metadata.csv')\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "#Remove .txt from filenames for merging\n",
    "metadata_df['Filename'] = metadata_df['Filename'].str.replace('.txt', '', regex=True)\n",
    "final_paper_df['Filename'] = final_paper_df['Filename'].str.replace('.txt', '', regex=True)\n",
    "\n",
    "#Merge metadata into main DataFrame\n",
    "final_paper_df = metadata_df.merge(final_paper_df, on='Filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29825966-7982-4662-925f-2535c35e5556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "#Load spaCy NLP Model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdcad74f-0c40-47a3-9ebe-eee9a41ae71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization, Lemmas, POS, NER\n",
    "def annotate_text(text):\n",
    "    \"\"\"Return tokens, lemmas, and POS tags for a given text string.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    return tokens, lemmas, pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b7504b6-ae63-4ff6-b02c-b9537bddc93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply annotation\n",
    "final_paper_df[['Tokens', 'Lemmas', 'POS']] = final_paper_df['Text'].apply(lambda x: pd.Series(annotate_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "216872e5-69aa-4274-a039-f1c7377929c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proper nouns and named entities\n",
    "def extract_proper_nouns(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc if token.pos_ == 'PROPN']\n",
    "\n",
    "def extract_named_entities(text):\n",
    "    doc = nlp(text)\n",
    "    return [ent.label_ for ent in doc.ents]\n",
    "\n",
    "def extract_ne_words(text):\n",
    "    doc = nlp(text)\n",
    "    return [ent.text for ent in doc.ents]\n",
    "\n",
    "final_paper_df['Proper_Nouns'] = final_paper_df['Text'].apply(extract_proper_nouns)\n",
    "final_paper_df['Named_Entities'] = final_paper_df['Text'].apply(extract_named_entities)\n",
    "final_paper_df['NE_Words'] = final_paper_df['Text'].apply(extract_ne_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c67272-c022-4131-ae6b-8234d787792f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Document</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Lemmas</th>\n",
       "      <th>POS</th>\n",
       "      <th>Proper_Nouns</th>\n",
       "      <th>Named_Entities</th>\n",
       "      <th>NE_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>song1</td>\n",
       "      <td>When The Sun Goes Down</td>\n",
       "      <td>Arctic Monkeys</td>\n",
       "      <td>2006</td>\n",
       "      <td>I said, who's that girl there?\\nI wonder what ...</td>\n",
       "      <td>i said, who is that girl there? i wonder what ...</td>\n",
       "      <td>[i, said, ,, who, is, that, girl, there, ?, i,...</td>\n",
       "      <td>[I, say, ,, who, be, that, girl, there, ?, I, ...</td>\n",
       "      <td>[PRON, VERB, PUNCT, PRON, AUX, DET, NOUN, ADV,...</td>\n",
       "      <td>[roxanne, mr, ., inconspicuous, givin]</td>\n",
       "      <td>[CARDINAL, TIME, PERSON, ORG, PERSON, DATE, CA...</td>\n",
       "      <td>[half, the night, roxanne, ford, inconspicuous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>song2</td>\n",
       "      <td>Fluorescent Adolescent</td>\n",
       "      <td>Arctic Monkeys</td>\n",
       "      <td>2007</td>\n",
       "      <td>You used to get it in your fishnets\\nNow you o...</td>\n",
       "      <td>you used to get it in your fishnets now you on...</td>\n",
       "      <td>[you, used, to, get, it, in, your, fishnets, n...</td>\n",
       "      <td>[you, use, to, get, it, in, your, fishnet, now...</td>\n",
       "      <td>[PRON, VERB, PART, VERB, PRON, ADP, PRON, NOUN...</td>\n",
       "      <td>[mary, mecca, dauber, flo, mary]</td>\n",
       "      <td>[TIME, TIME]</td>\n",
       "      <td>[night, night]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>song3</td>\n",
       "      <td>The Jeweller's Hands</td>\n",
       "      <td>Arctic Monkeys</td>\n",
       "      <td>2009</td>\n",
       "      <td>Fiendish wonder in the carnival's wake\\nDull c...</td>\n",
       "      <td>fiendish wonder in the carnival's wake dull ca...</td>\n",
       "      <td>[fiendish, wonder, in, the, carnival, 's, wake...</td>\n",
       "      <td>[fiendish, wonder, in, the, carnival, 's, wake...</td>\n",
       "      <td>[ADJ, NOUN, ADP, DET, NOUN, PART, ADJ, ADJ, NO...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[NORP, TIME]</td>\n",
       "      <td>[fiendish, the night]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>song4</td>\n",
       "      <td>Piledriver Waltz</td>\n",
       "      <td>Arctic Monkeys</td>\n",
       "      <td>2011</td>\n",
       "      <td>I etched the face of a stopwatch on the back o...</td>\n",
       "      <td>i etched the face of a stopwatch on the back o...</td>\n",
       "      <td>[i, etched, the, face, of, a, stopwatch, on, t...</td>\n",
       "      <td>[I, etch, the, face, of, a, stopwatch, on, the...</td>\n",
       "      <td>[PRON, VERB, DET, NOUN, ADP, DET, NOUN, ADP, D...</td>\n",
       "      <td>[amber]</td>\n",
       "      <td>[TIME, TIME]</td>\n",
       "      <td>[this morning, this morning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>song5</td>\n",
       "      <td>R U Mine?</td>\n",
       "      <td>Arctic Monkeys</td>\n",
       "      <td>2012</td>\n",
       "      <td>I'm a puppet on a string\\nTracy Island, time-t...</td>\n",
       "      <td>i am a puppet on a string tracy island, time-t...</td>\n",
       "      <td>[i, am, a, puppet, on, a, string, tracy, islan...</td>\n",
       "      <td>[I, be, a, puppet, on, a, string, tracy, islan...</td>\n",
       "      <td>[PRON, AUX, DET, NOUN, ADP, DET, NOUN, PROPN, ...</td>\n",
       "      <td>[tracy]</td>\n",
       "      <td>[CARDINAL, DATE, DATE, DATE, TIME, DATE, TIME,...</td>\n",
       "      <td>[four, years, days, tomorrow, tonight, tomorro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>song6</td>\n",
       "      <td>Star Treatment</td>\n",
       "      <td>Arctic Monkeys</td>\n",
       "      <td>2018</td>\n",
       "      <td>I just wanted to be one of The Strokes\\nNow lo...</td>\n",
       "      <td>i just wanted to be one of the strokes now loo...</td>\n",
       "      <td>[i, just, wanted, to, be, one, of, the, stroke...</td>\n",
       "      <td>[I, just, want, to, be, one, of, the, stroke, ...</td>\n",
       "      <td>[PRON, ADV, VERB, PART, AUX, NUM, ADP, DET, NO...</td>\n",
       "      <td>[bandana, jukebox]</td>\n",
       "      <td>[CARDINAL, DATE, DATE, DATE, TIME, PERSON, DAT...</td>\n",
       "      <td>[half, 1984, 2019, '70s, tonight, jukebox, '70...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename                   Title          Author  Year  \\\n",
       "0    song1  When The Sun Goes Down  Arctic Monkeys  2006   \n",
       "1    song2  Fluorescent Adolescent  Arctic Monkeys  2007   \n",
       "2    song3    The Jeweller's Hands  Arctic Monkeys  2009   \n",
       "3    song4        Piledriver Waltz  Arctic Monkeys  2011   \n",
       "4    song5               R U Mine?  Arctic Monkeys  2012   \n",
       "5    song6          Star Treatment  Arctic Monkeys  2018   \n",
       "\n",
       "                                            Document  \\\n",
       "0  I said, who's that girl there?\\nI wonder what ...   \n",
       "1  You used to get it in your fishnets\\nNow you o...   \n",
       "2  Fiendish wonder in the carnival's wake\\nDull c...   \n",
       "3  I etched the face of a stopwatch on the back o...   \n",
       "4  I'm a puppet on a string\\nTracy Island, time-t...   \n",
       "5  I just wanted to be one of The Strokes\\nNow lo...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  i said, who is that girl there? i wonder what ...   \n",
       "1  you used to get it in your fishnets now you on...   \n",
       "2  fiendish wonder in the carnival's wake dull ca...   \n",
       "3  i etched the face of a stopwatch on the back o...   \n",
       "4  i am a puppet on a string tracy island, time-t...   \n",
       "5  i just wanted to be one of the strokes now loo...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [i, said, ,, who, is, that, girl, there, ?, i,...   \n",
       "1  [you, used, to, get, it, in, your, fishnets, n...   \n",
       "2  [fiendish, wonder, in, the, carnival, 's, wake...   \n",
       "3  [i, etched, the, face, of, a, stopwatch, on, t...   \n",
       "4  [i, am, a, puppet, on, a, string, tracy, islan...   \n",
       "5  [i, just, wanted, to, be, one, of, the, stroke...   \n",
       "\n",
       "                                              Lemmas  \\\n",
       "0  [I, say, ,, who, be, that, girl, there, ?, I, ...   \n",
       "1  [you, use, to, get, it, in, your, fishnet, now...   \n",
       "2  [fiendish, wonder, in, the, carnival, 's, wake...   \n",
       "3  [I, etch, the, face, of, a, stopwatch, on, the...   \n",
       "4  [I, be, a, puppet, on, a, string, tracy, islan...   \n",
       "5  [I, just, want, to, be, one, of, the, stroke, ...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  [PRON, VERB, PUNCT, PRON, AUX, DET, NOUN, ADV,...   \n",
       "1  [PRON, VERB, PART, VERB, PRON, ADP, PRON, NOUN...   \n",
       "2  [ADJ, NOUN, ADP, DET, NOUN, PART, ADJ, ADJ, NO...   \n",
       "3  [PRON, VERB, DET, NOUN, ADP, DET, NOUN, ADP, D...   \n",
       "4  [PRON, AUX, DET, NOUN, ADP, DET, NOUN, PROPN, ...   \n",
       "5  [PRON, ADV, VERB, PART, AUX, NUM, ADP, DET, NO...   \n",
       "\n",
       "                             Proper_Nouns  \\\n",
       "0  [roxanne, mr, ., inconspicuous, givin]   \n",
       "1        [mary, mecca, dauber, flo, mary]   \n",
       "2                                      []   \n",
       "3                                 [amber]   \n",
       "4                                 [tracy]   \n",
       "5                      [bandana, jukebox]   \n",
       "\n",
       "                                      Named_Entities  \\\n",
       "0  [CARDINAL, TIME, PERSON, ORG, PERSON, DATE, CA...   \n",
       "1                                       [TIME, TIME]   \n",
       "2                                       [NORP, TIME]   \n",
       "3                                       [TIME, TIME]   \n",
       "4  [CARDINAL, DATE, DATE, DATE, TIME, DATE, TIME,...   \n",
       "5  [CARDINAL, DATE, DATE, DATE, TIME, PERSON, DAT...   \n",
       "\n",
       "                                            NE_Words  \n",
       "0  [half, the night, roxanne, ford, inconspicuous...  \n",
       "1                                     [night, night]  \n",
       "2                              [fiendish, the night]  \n",
       "3                       [this morning, this morning]  \n",
       "4  [four, years, days, tomorrow, tonight, tomorro...  \n",
       "5  [half, 1984, 2019, '70s, tonight, jukebox, '70...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save as CSV\n",
    "output_csv = os.path.join(corpus_path, 'annotated_dataset.csv')\n",
    "final_paper_df.to_csv(output_csv, index=False)\n",
    "\n",
    "final_paper_df.head(6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
